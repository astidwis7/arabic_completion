{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astidwis7/arabic_completion/blob/main/arabicCompletion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Python program to complete bald Arabic using Bidirectional LSTM***"
      ],
      "metadata": {
        "id": "xKszMNKYhIE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to open the dataset --> [arabic](https://drive.google.com/drive/folders/1s9HRTWmM2t5DR1-lIyzed09Z5bwjysUN?usp=drive_link)"
      ],
      "metadata": {
        "id": "a8E_dgApCVTp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcKA4EPN_dn7"
      },
      "outputs": [],
      "source": [
        "# retrieve arabic data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "ribasti = pd.read_csv('arabic.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZGDz4NGDwGJ"
      },
      "outputs": [],
      "source": [
        "# windowing data \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "korpus = []\n",
        "for _ in ribasti['0']:\n",
        "  korpus.append(str(_))\n",
        "korpusan = \" \".join(korpus)\n",
        "\n",
        "korpus_harakat = []\n",
        "for _ in ribasti['1']:\n",
        "  korpus_harakat.append(str(_))\n",
        "korpusan_harakat = \" \".join(korpus_harakat)\n",
        "\n",
        "korpus2 = []\n",
        "korpusan2 = korpusan.split()\n",
        "for i in range(len(korpusan2)-7):\n",
        "  korpus2.append(\" \".join(korpusan2[i:i+7]))\n",
        "\n",
        "korpus2_h = []\n",
        "korpusan2_h = korpusan_harakat.split()\n",
        "for i in range(len(korpusan2_h)-7):\n",
        "  korpus2_h.append(\" \".join(korpusan2_h[i:i+7]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XfwiL4uE_7P"
      },
      "outputs": [],
      "source": [
        "# tokenization with keras tokenizer\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "token_x = Tokenizer()\n",
        "token_y = Tokenizer()\n",
        "\n",
        "token_x.fit_on_texts(korpus2)\n",
        "token_y.fit_on_texts(korpus2_h)\n",
        "\n",
        "x_seq = token_x.texts_to_sequences(korpus2)\n",
        "y_seq = token_y.texts_to_sequences(korpus2_h)\n",
        "\n",
        "x_seq_padding = pad_sequences(x_seq, maxlen=7, padding=\"post\")\n",
        "x = np.asarray(x_seq_padding).astype(float)\n",
        "\n",
        "y_seq_padding = pad_sequences(y_seq, maxlen=7, padding=\"post\")\n",
        "y =  np.asarray(y_seq_padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM8jkTrmFmEy"
      },
      "outputs": [],
      "source": [
        "# Bidirectional LSTM model initiation\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, TimeDistributed, Bidirectional\n",
        "\n",
        "embedding_dim = 16\n",
        "\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Embedding(int(np.max(x)+1), embedding_dim, input_length=x.shape[1], input_shape=x.shape[1:]))\n",
        "classifier.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "classifier.add(TimeDistributed(Dense(64, activation='relu')))\n",
        "classifier.add(TimeDistributed(Dense(int(np.max(y)+1), activation='softmax')))\n",
        "\n",
        "classifier.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTkO-FRKFrOM",
        "outputId": "01c33a70-80cb-44a1-9fe3-e9a4b51b7392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "57695/57695 [==============================] - 1368s 24ms/step - loss: 3.4395 - accuracy: 0.4448 - val_loss: 3.7557 - val_accuracy: 0.4795\n",
            "Epoch 2/6\n",
            "57695/57695 [==============================] - 1364s 24ms/step - loss: 2.2980 - accuracy: 0.6036 - val_loss: 3.3963 - val_accuracy: 0.5301\n",
            "Epoch 3/6\n",
            "57695/57695 [==============================] - 1373s 24ms/step - loss: 1.8760 - accuracy: 0.6563 - val_loss: 3.2746 - val_accuracy: 0.5388\n",
            "Epoch 4/6\n",
            "57695/57695 [==============================] - 1381s 24ms/step - loss: 1.6167 - accuracy: 0.6892 - val_loss: 3.2174 - val_accuracy: 0.5509\n",
            "Epoch 5/6\n",
            "57695/57695 [==============================] - 1396s 24ms/step - loss: 1.4430 - accuracy: 0.7138 - val_loss: 3.2016 - val_accuracy: 0.5573\n",
            "Epoch 6/6\n",
            "57695/57695 [==============================] - 1425s 25ms/step - loss: 1.3269 - accuracy: 0.7321 - val_loss: 3.2120 - val_accuracy: 0.5601\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97f4fa1690>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# models training\n",
        "\n",
        "classifier.fit(x,y, batch_size=2, epochs=6, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save Bidirectional LSTM model\n",
        "\n",
        "# classifier.save_weights('arabic.h5')"
      ],
      "metadata": {
        "id": "_Mdzqt518ZP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict using saved model\n",
        "\n",
        "classifier.load_weights('arabic.h5')\n",
        "\n",
        "kalimat = token_x.texts_to_sequences(['b sm {ll~h {l r~Hm`n {l r~Hym'])\n",
        "kalimat_pad = pad_sequences(kalimat, maxlen=7, padding=\"post\")\n",
        "\n",
        "pred = classifier.predict(kalimat_pad)\n",
        "\n",
        "pred_ = []\n",
        "for i in range(7):\n",
        "  pred_.append([np.argmax(pred[0][i])])\n",
        "\n",
        "hasil = \" \".join(token_y.sequences_to_texts(pred__))\n",
        "hasil\n"
      ],
      "metadata": {
        "id": "Vymjfjpp5OpC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0628e731-94ef-47ec-a3d4-7ec1b2fc0fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'l r ahoma ni l r ahiymi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}